# Brief guide into finding similar source code with Apollo

### Environment

[Babelfish must be running and have Java driver installed.](https://doc.bblf.sh/user/getting-started.html)
Cassandra or ScyllaDB must be running.

### Prepare the source code

Apollo works with Git repositories stored in [Siva](https://github.com/src-d/go-siva) format.
Refer to [Borges](https://github.com/src-d/borges). We expect that the files will be in `/data` below.

### Index the files

We create the `OrderedDocumentFrequency` storing the index and global value 
frequencies of the features, `QuantizationLevels` models if need be, and a `DocumentFrequency` 
model which holds the index of all files.

```
apollo preprocess -r /data --cached-index-path index.asdf --docfreq docfreq.asdf \
    -f lit id uast2seq --uast2seq-seq-len 4 --uast2seq-weight 2 --min-docfreq 4 \
    -l Java Python --persist DISK_ONLY
```

> Docker users should add `--bblfsh bblfshd`.

More about [`preprocess`](cmd/preprocess.md).

### Extract the features

We convert every file into a [weighted set of features](https://en.wikipedia.org/wiki/Bag-of-words_model).
The batches for the `hash` command are written to `./bow*.asdf` (by default splitted by 2 GB).
We use three extractors: literals, identifiers and deterministic AST subpaths of size 4.
We double the importance of the latter features and throw away any values which appear 
in less than 4 files. Only Java source code is analysed. We optimize the pipeline 
executing by using the disk cache to save the [UASTs](https://doc.bblf.sh/uast/code-to-ast.html)
between each pass. The extracted bags are additionally saved in the database.

```
apollo bags -r /data --bow bow.asdf --docfreq docfreq.asdf --cached-index-path index.asdf \
    -f lit id uast2seq --uast2seq-seq-len 4 --uast2seq-weight 2 --min-docfreq 4 \
    -l Java Python --persist DISK_ONLY
```

> Docker users should add `--bblfsh bblfshd --cassandra cassandra`.

More about [`bags`](cmd/bags.md).

### Hash the samples

We hash the files which were converted into bags in the previous step and stored as several
`./bow*.asdf` files. The hashing parameters are written to `./params.asdf`.
The Weighted Jaccard Similarity threshold, which is the closer to 1 the less files are considered
similar, equals `0.8`. The hashtables are written to the database.

```
apollo hash 'bow*.asdf' -p params.asdf -t 0.8
```

> This step requires an NVIDIA GPU.

> Docker users should add `--cassandra=cassandra`.

More about [`hash`](cmd/hash.md).

### Query for a file

Given a Git hash of a file in the dataset, list the similar files:
```
apollo query -i <git hash>
```

> Docker users should add `--cassandra cassandra`.

More about [`query`](cmd/hash.md).

### Find groups of similar files

Find connected components in the resulting similarity graph and write them to `./cc.asdf`.

```
apollo cc -o cc.asdf
```

> Docker users should add `--cassandra cassandra`.

Run the default community detection algorithm and write the clusters to `./communities.asdf`.

```
apollo cmd -i cc.asdf -o communities.asdf
```

> Docker users should add `--cassandra cassandra`.

Output the report to stdout.

```
apollo dumpcmd communities.asdf
```

> Docker users should add `--cassandra cassandra`.

More about: [`cc`](cmd/cc.md), [`cmd`](cmd/cmd.md), [`dumpcmd`](cmd/dumpcmd.md).
